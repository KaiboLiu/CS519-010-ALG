CS 519  Algorithms  WINTER 2018
SOLUTION for MIDTERM REVIEW PROBLEMS

The Midterm will cover HWs 1-6 (with a focus on HWs 4-6) and Quizzes 1-2.

0. Give real-life examples of queue, stack, priority queue, hash-table, and binary search.

Answer:
priority queue: emergency room
hash-table & binary search: index at the end of each book

1. How do you use a priority queue to simulate (a) a queue and (b) a stack?

Answer:
Use the pushing index itself/its negative value as the key of this unit
to simulate a stack/queue.

2. What is the best complexity of internal sorting? 
   Why that complexity can _not_ be surpassed? (i.e., lowerbound)
   Name four (4) algorithms that achieve this complexity.

Answer:
Lowerbound: \Omega(nlogn).
There are n! permutations of a list with length n, and each comparison reduces the space
by half, so we need at least log(n!) comparison to get down to a single ordering.
Observe (0.5n)^(0.5n) < n! < n^n.
So log ((0.5n)^(0.5n)) < log(n!) < log(n^n).
So 0.5n log 0.5n < log(n!) < n log n.
So log(n!) = \Theta(nlogn).
Thus \Omega(nlogn) is the lower bound.

Quicksort; Mergesort; Heapsort; Balanced BST insertion sort.

3. Rank the growth functions from slowest to fastest:
   1, logn, n, nlogn, n^2, 2^n, n!, n^n

Answer: just that order. :)

4. Analyze the complexity for each of the following (use recursion tree method), and name an instance:
   (a) T(n) = 2T(n/2) + O(n)
   (b) T(n) = 2T(n/2) + O(1)
   (c) T(n) =  T(n/2) + O(n)
   (d) T(n) =  T(n/2) + O(1)
   (e) T(n) = 2T(n/2) + O(logn)

Note: you need to derive the most accurate complexity (i.e., \Theta instead of Big-O).

Answer:
(a) O(nlogn)  -- quicksort bestcase, mergesort
(b) O(n)      -- traversing a balanced binary tree
(c) O(n)      -- quickselect bestcase
(d) O(logn)   -- binary search, find in balanced binary search tree
(e) O(n)      -- heapify (see HW4 problem 0)

Note: some others:
(f) T(n) = T(n-1) + O(n)    -- O(n^2), quicksort/quickselect worst-case
(g) T(n) = T(n-1) + O(logn) -- O(nlogn), keep pushing instead of heapify
 
5. There are various implementations of priority queue:
   (a) binary heap
   (b) sorted array
   (c) unsorted array
   (d) sorted linkedlist
   (e) unsorted linkedlist

   Write the time complexities for the following operations for each of the above:
   (1) push
   (2) pop-min
   (3) peek-min (just output the min, without deleting it)
   (4) heapify   

Answer:
|--------------+-----------------+------------------+--------------------+-----------------------+-------------------------|
|              | (a) binary heap | (b) sorted array | (c) unsorted array | (d) sorted linkedlist | (e) unsorted linkedlist |
|--------------+-----------------+------------------+--------------------+-----------------------+-------------------------|
| (1) push     | O(logn)         | O(n)             | amortized O(1)     | O(n)                  | O(1)                    |
|--------------+-----------------+------------------+--------------------+-----------------------+-------------------------|
| (2) pop-min  | O(logn)         | amortized O(1) * | O(n)               | O(1)                  | O(n)                    |
|--------------+-----------------+------------------+--------------------+-----------------------+-------------------------|
| (3) peak-min | O(1)            | O(1)             | O(n) **            | O(1)                  | O(n) **                 |
|--------------+-----------------+------------------+--------------------+-----------------------+-------------------------|
| (4) heapify  | O(n)            | O(nlogn) ***     | O(n)               | O(nlogn) ***          | O(n)                    |
|--------------+-----------------+------------------+--------------------+-----------------------+-------------------------|

Note:
  * keep min at the end (if you keep min at the front, then pop-min is O(n))
 ** if you further keep track of min position, then peak-min would be O(1). 
    remember to update that min position in push (still O(1)) and pop-min (still O(n)).
*** the input list is unsorted, so you need to sort it to make a priority queue.

See also:
https://www.cs.cmu.edu/~adamchik/15-121/lectures/Binary%20Heaps/heaps.html
http://cs.lmu.edu/~ray/notes/pqueues/

6. You have n matrices, each with nxn entries (so you have n^3 numbers in total).
   For each matrix A, the entries are sorted:
   A_ij < A_ik for each row i and all columns j<k.
   A_ij < A_kj for each column j and all rows i<k.
   
   Design the fastest algorithm to select the n smallest numbers from these n^3 numbers.
   Analyze time complexity.

Answer:
1) Heapify a heap H from each A_00, and a set S of each A_00 to avoid multiple pushing for one element. -- O(n)
2) Loop for n times:
   (x, i, j) = pop-min(H);   -- O(logn)
   try pushing two successor elements in the same matrix to H if they are not in S; update S. -- O(logn)

total: O(n + n logn) = O(nlogn) time complexity.

Note: Make sure you implement it yourself!

      Read HW4 nbestc solution!

7. Give (at least) two reasons why bubble-up is faster than bubble-down.

Answer:
reason 1: bubble-down needs more comparisons per step
reason 2: bubble-down path is non-deterministic (bubble-up path is deterministic)

8. Fibonacci. There are three implementations:
   (a) the naive recursive solution without memoization runs in time closest to:
       n, nlogn, n^2, a^n, n^a, 2^n, n!, n^n  (where 1<a<2)
   (b) implement the memoized recursive solution.
       What's the space and time complexities?
   (c) implement the O(1)-space solution (bottom-up).

Answer:
(a) a^n. (1<a<2) 
(b) O(n) in both time and space.

def fib(n, cache={0:1, 1:1}):
    if n in cache:
        return cache[n]
    cache[n] = fib(n-1, cache) + fib(n-2, cache)
    return cache[n]

(c) 

def fib(n):
    a, b = 1, 1
    for _ in xrange(n):
        a, b = b, a+b
    return b

9. The DP question will be very similar to unbounded and bounded knapsack.
   It will include:
   (a) greedy solution
   (b) counter-example
   (c) subproblem
   (d) recurrence
   (e) time and space complexity
   (f) is there an alternative solution without smaller space complexity?